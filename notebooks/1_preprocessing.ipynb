{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separate-devon",
   "metadata": {},
   "source": [
    "# Using HDX_LIMIT Part 1: Preprocessing\n",
    "***\n",
    "\n",
    "**The purpose of this notebook is to provide explanation and usage examples for the modules of the preprocessing subpackage of the HDX_LIMIT package.**\n",
    "\n",
    ">The preprocessing subpackage is used to search HDX-LC-IMS-MS data for signal that could plausibly correspond to known-injected-protein sequences. The final product of the Preprocessing subpackage is library_info.csv, a list of observed charged-species from the data that reasonably correspond to expected values for library proteins.\n",
    "\n",
    "**The preprocessing modules are the start of the analytical pipeline and require a set of initial inputs:**\n",
    "1. .mzML files generated from Waters .RAW files for all replicates of all hdx time points. ProteoWizard msconvert is used for conversion. \n",
    "2. .peaks.isotopes files generated with IMTBX+Grppr from all .mzML replicates of the undeuterated hdx-timepoint, not yet available as a Docker image - windows only\n",
    "3. A .csv file of all library proteins with 'name' and 'sequence' columns, with sequences in single-letter amino acid notation.\n",
    "4. A dictionary (.yaml if using Snakemake or command-line) with the key 'timepoints' corresponding to a list of the hdx time points in integer seconds, and where each integer entry in 'timepoints' is a key corresponding to the filepaths for all replicate .mzML files for that time point. \n",
    "\n",
    "**These inputs are used by the modules of the preprocessing subpackage to generate several intermediate files which are used to generate the library_info.csv master list of identified library protein charged-species and their positions within each dimension of separation:**\n",
    "-  Total Ionic Current (tic) files for all hdx time point replicate .mzML files, used with dynamic time-warping to estimate LC-elution times in later hdx time points.\n",
    "-  .csv lists of library protein charge-states observed for each imtbx .peaks.isotopes file\n",
    "\n",
    "**The master list is created from initial inputs and the above intermediates, and it is fed forward as input to the pipeline modules along with gzipped versions of the .mzML files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "increasing-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Set matplotlib backend to work in jupyter\n",
    "import matplotlib\n",
    "# matplotlib.use(\"nbAgg\") # best for windows but works on Mac\n",
    "matplotlib.use(\"MacOSX\") # best for notebooks on Mac\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make the Jupyter environment see workflow/scripts/.\n",
    "sys.path.append(\"/\".join(os.getcwd().split(\"/\")[:-1])+\"/workflow/scripts\") # default 'path/to/HDX_LIMIT-Pipeline/workflow/scripts/'\n",
    "config = yaml.load(open(\"../config/config.yaml\", \"rb\").read(), Loader=yaml.FullLoader)\n",
    "\n",
    "# Load and alias main functions of preprocessing modules\n",
    "from HDX_LIMIT.preprocessing.imtbx_reader import main as imtbx_reader\n",
    "from HDX_LIMIT.preprocessing.make_ims_mz_tics import main as make_ims_mz_tics\n",
    "from HDX_LIMIT.preprocessing.gzip_mzml import main as gzip_mzml\n",
    "from HDX_LIMIT.preprocessing.make_library_master_list import main as make_library_master_list\n",
    "\n",
    "from HDX_LIMIT.io import limit_read, limit_write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-briefing",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Making Total Ionic Current (TIC) representations\n",
    "\n",
    "Our identification assumes that LC-elution and IMS-drift times will be near-invariate over the course of the HDX time series, and we use this to compensate for uncertainty in mass when identifying at later HDX time points. \n",
    "\n",
    "LC-elution order is assumed to be preserved between runs, but not elution-time. We use the fastdtw dynamic time-warping algorithm to map from the undeuterated ground-truth elution times to the unknown elution times of the later HDX time points.\n",
    "\n",
    "We downsample the undeuterated .mzML files into .tic files to lower the expense of the dynamic time-warping algorithm used to map undeuterated LC-profiles to later timepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stock-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function main in module HDX_LIMIT.preprocessing.make_ims_mz_tics:\n",
      "\n",
      "main(mzml_path, return_flag=None, out_path=None)\n",
      "    Generate LC Chromatogram by summing ionic current over IMS and m/Z dimensions.\n",
      "    \n",
      "    Args:\n",
      "        mzml_path (string): path/to/file.mzml to be read into .tic\n",
      "        return_flag: option to return main output in python, for notebook context\n",
      "        out_path (string): option to save main output, path/to/file.tic\n",
      "    \n",
      "    Returns:\n",
      "        ms1_ims_tic (np_array): LC Chromatogram as 2D numpy ndarray. Contains sum of ionic current for LC-RT and m/Z bins.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_ims_mz_tics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regular-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a .tic file for an undeuterated timepoint if it's not already present.\n",
    "if \"../resources/tics/180604_Mix2_MES_nonlin_UN.mzML.ims.mz.tic\" not in glob.glob(\"../resources/tics/*.tic\"):\n",
    "    un_tic = make_ims_mz_tics(\"../resources/mzml/180604_Mix2_MES_nonlin_UN.mzML\", out_path=\"../resources/tics/180604_Mix2_MES_nonlin_UN.mzML.ims.mz.tic\", return_flag=True)\n",
    "else:\n",
    "    un_tic = np.loadtxt(\"../resources/tics/180604_Mix2_MES_nonlin_UN.mzML.ims.mz.tic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "neither-essex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 69.0, 'Liquid chromatography (LC) elution time bins'),\n",
       " Text(123.0, 0.5, 'Mass/Charge (m/Z) bins')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The downsampled .tic will be used to map the LC-elution profiles of each later timepoint replicate to the undeuterated ground-truth values.\n",
    "# The heatmap will be mostly dark because of the ~1e6 magnitude of the abundant protein signals.\n",
    "# Dimensions of tic are LC-bins and m/Z bins\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1 = sns.heatmap(un_tic, ax=ax1)\n",
    "ax1.set(xlabel=\"Liquid chromatography (LC) elution time bins\", ylabel = \"Mass/Charge (m/Z) bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-aurora",
   "metadata": {},
   "source": [
    "***\n",
    "## Making identification lists from imtbx .peaks.isotopes files\n",
    "\n",
    "IMTBX + Grppr produce the .peaks.isotopes file, which is a list of observed peaks and their positions for a single undeuterated .mzML file. \n",
    "\n",
    "We cross-reference this list of all charged species signals with the expected masses of library proteins. \n",
    "\n",
    "The filtered .peaks.isotopes entries are returned as a Pandas-ready dictionary (.csv in snakemake and command-line) and the undeuterated lists are combined in the make_library_master_list module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neural-authentication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function main in module HDX_LIMIT.preprocessing.imtbx_reader:\n",
      "\n",
      "main(isotopes_path, names_and_seqs_path, out_path=None, return_flag=None, original_mz_kde_path=None, adjusted_mz_kde_path=None, calibration_outpath=None, polyfit_deg=1, ppm_tolerance=50, intensity_tolerance=10000, cluster_corr_tolerance=0.99, ppm_refilter=10)\n",
      "    Reads IMTBX file and clusters identified signals with close physical values. \n",
      "    \n",
      "    Args:\n",
      "        isotopes_path (string): path/to/.peaks.isotopes file from undeuterated mzml\n",
      "        names_and_seqs_path (string): path/to/.csv with names and sequences of library proteins\n",
      "        out_path (string): path/to/_intermediate.csv main output file\n",
      "        return_flag (non-None): option to return main output in Python, for notebook context\n",
      "        original_mz_kde_path (string): /path/to/file to save original mz-error kde plots\n",
      "        adjusted_mz_kde_path (string): /path/to/file to save adjusted mz-error kde plots\n",
      "        calibration_outpath (string): /path/to/file for polyfit-calibration output, determines use of polyfit calibration\n",
      "        polyfit_deg (int): degree of polynomial curve to fit to mz data for non-linear correction\n",
      "        ppm_tolerance (float): ppm error tolerance of observed to expected mz, defualt 50 ppm\n",
      "        intensity_tolerance (float): minimum intensity to consider cluster, default 10E4\n",
      "        cluster_corr_tolerance (float): minimum correlation between isotope clusters to consider them redundant, default 0.99\n",
      "        ppm_refilter (float): ppm error tolerance for post-mz-adjustment clusters, default 10 ppm\n",
      "    \n",
      "    Returns:\n",
      "        sum_df (Pandas DataFrame): DF of all charges passing filtration, to be combined with other undeuterated outputs in make_library_master_list.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(imtbx_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indoor-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an imtbx intermediate file for an undeuterated timepoint if it's not already present.\n",
    "if \"../resources/imtbx/180604_Mix2_MES_nonlin_UN.mzML_intermediate.csv\" not in glob.glob(\"../resources/imtbx/*.csv\"):\n",
    "    imtbx_intermediate_UN = imtbx_reader(\"../resources/isotopes/180604_Mix2_MES_nonlin_UN.mzML.peaks.isotopes\", \"../resources/library_info/new_HX_order.csv\", out_path=\"../resources/isotopes/180604_Mix2_MES_nonlin_UN.mzML_intermediate.csv\", return_flag=True)\n",
    "else:\n",
    "    imtbx_intermediate_UN = pd.read_csv(\"../resources/imtbx/180604_Mix2_MES_nonlin_UN.mzML_intermediate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lasting-elephant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RT</th>\n",
       "      <th>im_mono</th>\n",
       "      <th>ab_cluster_total</th>\n",
       "      <th>MW</th>\n",
       "      <th>charge</th>\n",
       "      <th>expect_mz</th>\n",
       "      <th>obs_mz</th>\n",
       "      <th>ppm</th>\n",
       "      <th>abs_ppm</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEEH_rd1_0125.pdb</td>\n",
       "      <td>4.458056</td>\n",
       "      <td>116.508605</td>\n",
       "      <td>3010934.8</td>\n",
       "      <td>5238.760347</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1048.759339</td>\n",
       "      <td>1048.758083</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.197974</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HHH_rd4_0891.pdb</td>\n",
       "      <td>4.349178</td>\n",
       "      <td>118.225656</td>\n",
       "      <td>207025.7</td>\n",
       "      <td>5649.892150</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1130.985700</td>\n",
       "      <td>1130.985611</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.079082</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEEH_rd1_0125.pdb</td>\n",
       "      <td>4.439518</td>\n",
       "      <td>89.788979</td>\n",
       "      <td>703478.1</td>\n",
       "      <td>5238.760347</td>\n",
       "      <td>6.0</td>\n",
       "      <td>874.133994</td>\n",
       "      <td>874.131069</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>3.346653</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEEH_rd1_0966.pdb</td>\n",
       "      <td>4.384746</td>\n",
       "      <td>101.893880</td>\n",
       "      <td>476410.9</td>\n",
       "      <td>5648.896896</td>\n",
       "      <td>6.0</td>\n",
       "      <td>942.490086</td>\n",
       "      <td>942.488971</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.183368</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEEH_rd1_0966.pdb</td>\n",
       "      <td>4.406459</td>\n",
       "      <td>118.695357</td>\n",
       "      <td>258016.0</td>\n",
       "      <td>5648.896896</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1130.786649</td>\n",
       "      <td>1130.789337</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.376841</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>HEEH_rd4_0276.pdb</td>\n",
       "      <td>18.797200</td>\n",
       "      <td>102.958674</td>\n",
       "      <td>252871.5</td>\n",
       "      <td>5071.781584</td>\n",
       "      <td>6.0</td>\n",
       "      <td>846.304201</td>\n",
       "      <td>846.300142</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>4.795363</td>\n",
       "      <td>7097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>HEEH_rd4_0276.pdb</td>\n",
       "      <td>18.824251</td>\n",
       "      <td>90.896216</td>\n",
       "      <td>199883.9</td>\n",
       "      <td>5071.781584</td>\n",
       "      <td>6.0</td>\n",
       "      <td>846.304201</td>\n",
       "      <td>846.300228</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>4.693881</td>\n",
       "      <td>7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>HHH_rd1_0014.pdb</td>\n",
       "      <td>18.717667</td>\n",
       "      <td>124.237793</td>\n",
       "      <td>306718.5</td>\n",
       "      <td>6124.201519</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1225.847574</td>\n",
       "      <td>1225.853444</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.788921</td>\n",
       "      <td>7102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>HEEH_rd4_0528.pdb</td>\n",
       "      <td>19.364049</td>\n",
       "      <td>182.543280</td>\n",
       "      <td>276702.2</td>\n",
       "      <td>4958.772975</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1240.700514</td>\n",
       "      <td>1240.702833</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.869200</td>\n",
       "      <td>7115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>HHH_rd4_0269.pdb</td>\n",
       "      <td>19.004371</td>\n",
       "      <td>124.147824</td>\n",
       "      <td>64920.9</td>\n",
       "      <td>6123.235948</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1225.654460</td>\n",
       "      <td>1225.655825</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.113857</td>\n",
       "      <td>7118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1881 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name         RT     im_mono  ab_cluster_total           MW  \\\n",
       "0     HEEH_rd1_0125.pdb   4.458056  116.508605         3010934.8  5238.760347   \n",
       "1      HHH_rd4_0891.pdb   4.349178  118.225656          207025.7  5649.892150   \n",
       "2     HEEH_rd1_0125.pdb   4.439518   89.788979          703478.1  5238.760347   \n",
       "3     HEEH_rd1_0966.pdb   4.384746  101.893880          476410.9  5648.896896   \n",
       "4     HEEH_rd1_0966.pdb   4.406459  118.695357          258016.0  5648.896896   \n",
       "...                 ...        ...         ...               ...          ...   \n",
       "1876  HEEH_rd4_0276.pdb  18.797200  102.958674          252871.5  5071.781584   \n",
       "1877  HEEH_rd4_0276.pdb  18.824251   90.896216          199883.9  5071.781584   \n",
       "1878   HHH_rd1_0014.pdb  18.717667  124.237793          306718.5  6124.201519   \n",
       "1879  HEEH_rd4_0528.pdb  19.364049  182.543280          276702.2  4958.772975   \n",
       "1880   HHH_rd4_0269.pdb  19.004371  124.147824           64920.9  6123.235948   \n",
       "\n",
       "      charge    expect_mz       obs_mz  ppm   abs_ppm  cluster  \n",
       "0        5.0  1048.759339  1048.758083 -1.2  1.197974      111  \n",
       "1        5.0  1130.985700  1130.985611 -0.1  0.079082      139  \n",
       "2        6.0   874.133994   874.131069 -3.3  3.346653      162  \n",
       "3        6.0   942.490086   942.488971 -1.2  1.183368      167  \n",
       "4        5.0  1130.786649  1130.789337  2.4  2.376841      228  \n",
       "...      ...          ...          ...  ...       ...      ...  \n",
       "1876     6.0   846.304201   846.300142 -4.8  4.795363     7097  \n",
       "1877     6.0   846.304201   846.300228 -4.7  4.693881     7100  \n",
       "1878     5.0  1225.847574  1225.853444  4.8  4.788921     7102  \n",
       "1879     4.0  1240.700514  1240.702833  1.9  1.869200     7115  \n",
       "1880     5.0  1225.654460  1225.655825  1.1  1.113857     7118  \n",
       "\n",
       "[1881 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imtbx_intermediate_UN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-garlic",
   "metadata": {},
   "source": [
    "***\n",
    "## Making the master list of library protein signals\n",
    "\n",
    "The main output of the preprocessing subpackage is library_info.csv:<br>\n",
    ">A list of all signals observed in the undeuterated MS experiments with masses corresponding to library proteins and their expected locations in LC elution time at later HDX timepoints. \n",
    "\n",
    "The master list is created from the imtbx intermediate lists of identified signals, and TICs of each MS-run. The lists are combined and filtered for duplicates, and the TICs are used in prediction of LC-elution time for deuterated timepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "featured-behalf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function main in module HDX_LIMIT.preprocessing.make_library_master_list:\n",
      "\n",
      "main(names_and_seqs_path, undeut_mzml, intermediates, tics, timepoints, return_flag=None, out_path=None, rt_group_cutoff=0.2, plot=None)\n",
      "    Generates the master list of library_proteins identified in MS data: library_info.csv.\n",
      "    \n",
      "    Args:\n",
      "        names_and_seqs_path (string): path/to/names_and_seqs.csv\n",
      "        undeut_mzml (string): path/to/undeuterated.mzML\n",
      "        intermediates (list of strings): list of paths to imtbx intermediate files\n",
      "        tics (list of strings): list of paths to all .tic files\n",
      "        timepoints (dict): dictionary with 'timepoints' key containing list of hdx timepoints in integer seconds, which are keys mapping to lists of each timepoint's replicate .mzML filenames \n",
      "        return_flag (any non-None type): option to return main output in python, for notebook context\n",
      "        out_path (string): path/to/file for main output library_info.csv\n",
      "        rt_group_cutoff (float): radius in LC-RT to consider signals a part of an rt-cluster\n",
      "        plot (any non-None type): path/to/file for stretched time plots\n",
      "    \n",
      "    Returns:\n",
      "        library_info (dict): Outputs library_info as dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_library_master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "analyzed-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = [\"../resources/imtbx/180604_Mix2_MES_nonlin_UN.mzML_intermediate.csv\", \n",
    "                 \"../resources/imtbx/180604_Mix2_MES_nonlin_UN2.mzML_intermediate.csv\", \n",
    "                 \"../resources/imtbx/180604_Mix2_MES_nonlin_UN3.mzML_intermediate.csv\"]\n",
    "tics = glob.glob(\"../resources/tics/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ultimate-harvest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rwl0960/opt/anaconda3/envs/dask_lab/lib/python3.7/site-packages/numpy/lib/function_base.py:380: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/Users/rwl0960/opt/anaconda3/envs/dask_lab/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../resources/mzml/180604_Mix2_MES_nonlin_UN.mzML'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e10598a64873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This can take a long time to run depending on the number of identifications from imtbx.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_library_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_library_master_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../resources/library_info/new_HX_order.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../resources/mzml/180604_Mix2_MES_nonlin_UN.mzML'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../resources/test_library_info.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/hdx/HDX_LIMIT-Pipeline/workflow/scripts/HDX_LIMIT/preprocessing/make_library_master_list.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(names_and_seqs_path, undeut_mzml, intermediates, tics, timepoints, return_flag, out_path, rt_group_cutoff, plot)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mstretched_ts1_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstretched_ts2_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_stretched_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0mlo_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lc_timepoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_global_scan_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundeut_mzml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m# merge UNs - no, appends open dfs to list, why?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/hdx/HDX_LIMIT-Pipeline/workflow/scripts/HDX_LIMIT/preprocessing/make_library_master_list.py\u001b[0m in \u001b[0;36mset_global_scan_bounds\u001b[0;34m(mzml)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymzml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmzml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0mn_scans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spectrum_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mlc_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_scans\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dask_lab/lib/python3.7/site-packages/pymzml/run.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_file, MS_precisions, obo_version, build_index_from_scratch, skip_chromatogram, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guess_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_object\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offset_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_object\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobo_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dask_lab/lib/python3.7/site-packages/pymzml/run.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(self, path_or_file)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mbuild_index_from_scratch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_index_from_scratch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dask_lab/lib/python3.7/site-packages/pymzml/file_interface.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, encoding, build_index_from_scratch)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_index_from_scratch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_index_from_scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dask_lab/lib/python3.7/site-packages/pymzml/file_interface.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path_or_file)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstandardGzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardGzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         return standardMzml.StandardMzml(\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_index_from_scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         )\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dask_lab/lib/python3.7/site-packages/pymzml/file_classes/standardMzml.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, encoding, build_index_from_scratch)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_open\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregex_patterns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPECTRUM_OPEN_PATTERN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dask_lab/lib/python3.7/site-packages/pymzml/file_classes/standardMzml.py\u001b[0m in \u001b[0;36mget_file_handler\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_file_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dask_lab/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../resources/mzml/180604_Mix2_MES_nonlin_UN.mzML'"
     ]
    }
   ],
   "source": [
    "# This can take a long time to run depending on the number of identifications from imtbx.\n",
    "test_library_info = make_library_master_list(\"../resources/library_info/new_HX_order.csv\", \"../resources/mzml/180604_Mix2_MES_nonlin_UN.mzML\", intermediates, tics, config, return_flag=True, out_path=\"../resources/test_library_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_library_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-purple",
   "metadata": {},
   "source": [
    "***\n",
    "## Gzipping .mzMLs\n",
    "\n",
    "The HDX_LIMIT.preprocessing.gzip_mzml module is a wrapper script for the pymzml.utils.utils.index_gzip function, which saves a .mzML file in a randomly accessible format. \n",
    "\n",
    "These .mzML.gz files are used when extracting the identified signals from their expected locations in the pipeline subpackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "opposed-lightning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function main in module HDX_LIMIT.preprocessing.gzip_mzml:\n",
      "\n",
      "main(mzml_path, out_path=None)\n",
      "    Create an indexed, gzipped mzML.gz file from a .mzML file.\n",
      "    \n",
      "    Args:\n",
      "        mzml_path (string): path/to/file.mzML to be gzipped \n",
      "        out_path (string): path/to/file.mzML.gz - the gzipped .mzML output path\n",
      "    \n",
      "    Returns:\n",
      "        None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gzip_mzml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not return\n",
    "gzip_mzml(mzml_path='', outpath='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
