{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compressed-portugal",
   "metadata": {},
   "source": [
    "# Using HDX_LIMIT Part 3: Factorization and Generating HDX Time Series \n",
    "***\n",
    "\n",
    "The purpose of this notebook is to provide explanation and usage examples for the modules of the pipeline subpackage of the HDX_LIMIT package. \n",
    "\n",
    "**The pipeline subpackage is used to extract signal corresponding to library proteins from known positions in each HDX timepoint, and process those signals into a best-estimate HDX-mass-addition time series for each library protein.**\n",
    "\n",
    ">The subpackage relies on .mzML.gz files and library_info.csv from preprocessing, but no other inputs are needed.\n",
    "\n",
    ">The pipeline modules work on top of the HDX_LIMIT.datatypes and .processing core-modules, and are designed to be context-flexible for use in Snakemake, command-line, and python contexts. \n",
    "\n",
    "**The pipeline subpackage performs three main tasks, each to its own module:**\n",
    "1. Extracting protein signals from predetermined locations found in library_info.csv\n",
    "2. Packaging extracted signals into custom classes that perform deconvolution\n",
    "3. Selecting from pools of candidate signals to create a best-estimate HDX-mass-addition timeseries for each library protein identified.\n",
    "\n",
    "**The two 'IdotP' modules: idotp_check and idotp_filter, are used in Snakemake to reduce the number of candidate signals to be processed.** \n",
    ">The idotp_check Snakefile extracts signal from all undeuterated replicates for each entry in library_info.csv, uses the core classes to clean and deconvolute the data, and measures the quality of the observed signal against the theoretical isotopic distribution determined from the given protein's sequence. \n",
    "\n",
    ">The measure of quality used is the dot product between the observed and theoretical normalized integrated m/Z distributions (range [0,1]), or 'isotopic dot product' shortened to 'idotp'. A lower threshold on idotp is given to idotp_filter, which returns a set of indices from library_info.csv with idotp >= threshold. Lines in library_info.csv with poor idotp are not considered for further processing, crucially reducing computational load. \n",
    "\n",
    ">Default values for the idotp threshold are ~0.99 for extremely-high-confidence, and ~0.95 for high-confidence. Thresholds should be as close to 1 as possible to avoid excessive load and garbage-in-garbage-out problems, while retaining the highest identification-rate possible. The idotp_filter module creates plots of the idotp distribution, which help in making informed choices about idotp threshold.\n",
    "\n",
    "**The main output of the pipeline modules is the best-estimate hdx-mass-addition timeseries, contained in the PathOptimizer object as .winners, a list of IsotopeCluster objects. This is used in the estimation of per-residue exchange rates and $\\Delta G_{unfolding}$ of library proteins.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescribed-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Set matplotlib backend to work in jupyter.\n",
    "import matplotlib\n",
    "# matplotlib.use('nbAgg') # best for windows but works on Mac\n",
    "matplotlib.use('MacOSX') # best for notebooks on Mac\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make the Jupyter environment see workflow/scripts/.\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1])+'/workflow/scripts') # default 'path/to/HDX_LIMIT-Pipeline/workflow/scripts/'\n",
    "library_info = pd.read_csv('../resources/library_info/library_info.csv')\n",
    "config = yaml.load(open('../config/config.yaml', 'rb').read(), Loader=yaml.FullLoader)\n",
    "\n",
    "# Load and alias main functions of preprocessing modules\n",
    "from HDX_LIMIT.pipeline.idotp_check import main as idotp_check\n",
    "from HDX_LIMIT.pipeline.idotp_filter import main as idotp_filter\n",
    "from HDX_LIMIT.pipeline.extract_timepoint_tensors import main as extract_timepoint_tensors\n",
    "from HDX_LIMIT.pipeline.generate_tensor_ics import main as generate_tensor_ics\n",
    "from HDX_LIMIT.pipeline.optimize_paths import main as optimize_paths\n",
    "\n",
    "from HDX_LIMIT.io import limit_read, limit_write, optimize_paths_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-weight",
   "metadata": {},
   "source": [
    "**Here we consider groups of charged species together as an 'rt-group': a group of all the observed charge states of a library protein, clustered in LC retention time.**<br>\n",
    "This is necessary to limit the size of the LC extraction window, as our designed proteins have been observed to have bimodal elution profiles. Clustering by elution-time can produce several rt-groups for each library protein, but these can be filtered with the idotp_check module to reduce computational load. RT-group names are assigned during the creation of the library_info.csv, and here we create sub-dataframes from library_info for each rt_group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "utility-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide library_info into rt-group level dataframes\n",
    "lib_names = list(set(library_info['name'].values))\n",
    "lib_names = sorted(lib_names, key=lambda i: float(i.split('_')[-1]))\n",
    "\n",
    "rt_group_dfs = {}\n",
    "for name in lib_names:\n",
    "    rt_group_dfs[name] = library_info.loc[library_info['name']==name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-essence",
   "metadata": {},
   "source": [
    "## Cleaning and deconvoluting extracted signals\n",
    "\n",
    "**The generate_tensor_ics pipeline module is meant to fully abstract the signal processsing of the extracted tensors.** \n",
    "\n",
    ">Usually the only output is what will be used in generating the hdx-mass-addition time series: the list of IsotopeCluster objects identified from the input tensor. However in python contexts where the main function can be exposed (like this notebook), the return_flag argument can be used to return the TensorGenerator object from generate_tensor_ics. The TensorGenerator object contains a DataTensor object: the source of the IsotopeCluster objects, and more information than would be available with only the IsotopeCluster outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-photographer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
