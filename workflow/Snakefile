# Define config file and import libraries
configfile: "config/config.yaml"


import glob
import shutil
import pandas as pd
from collections import OrderedDict

# Read list of candidate POI charge states produced by preprocessing snakefile
library_info_fn = "resources/idotp_filter/checked_library_info.json"
library_info = pd.read_json(library_info_fn)

proc = glob.glob("resources/ic_time_series/*.zlib")
# names = [fn.split('_')[:-3] for fn in proc]
names = list(set(library_info["name"].values))
idotp_check_indices = pd.read_csv("resources/idotp_filter/filter_passing_indices.csv")['index'].values
names_with_indices = [name for name in names if any(True for idx in library_info.loc[library_info["name"]==name].index if idx in idotp_check_indices)]
print("Protein Names: "+str(len(names))+", Names with indices: "+str(len(names_with_indices)))

# all rule defines default snakefile call without specification of rule: "snakemake" vs. "snakemake -s path/to/alt/snakefile"
rule all:
    input:
        expand("resources/ic_time_series/{name}_winner.cpickle.zlib", name=names_with_indices)
        #expand("results/plots/ic_time_series/gjr_plots/{name}_gjr_plot.pdf", name=names),  #config['run_name']+"_plot_linker.html"


def optimize_paths_inputs(name, library_info, idotp_check_indices):
    # Pass inputs as fxn of rt-group name wildcard. Creates analyze_tensor() input filenames in fixed pattern, input tensor names include library_info.index and rt-group avg elution time.
    name_inputs = []
    for key in config["timepoints"]:
        if len(config[key]) > 1:
            for file in config[key]:
                passing_indices = [i for i in library_info.loc[library_info["name"]==name].index if i in idotp_check_indices]
                for idx in passing_indices:
                    name_inputs.append(
                        "resources/subtensor_ics/"
                        + str(idx)
                        + "/"
                        + str(idx)
                        + "_"
                        + file
                        + ".gz.cpickle.zlib"
                    )  
        else:
            file = config[key][0]
            passing_indices = [i for i in library_info.loc[library_info["name"]==name].index if i in idotp_check_indices]
            for idx in passing_indices:
                name_inputs.append(
                    "resources/subtensor_ics/"
                    + str(idx)
                    + "/"
                    + str(idx)
                    + "_"
                    + file
                    + ".gz.cpickle.zlib"
                )

    return name_inputs

rule mv_passing_tensors:
# Move tensors that pass 
    input:
        sorted(expand("resources/tensors/{lib_idx}/{lib_idx}_{mzml}.gz.cpickle.zlib", lib_idx=idotp_check_indices, mzml=[fn for fn in config[0]]))
    output:
        sorted(expand("resources/passing_tensors/{lib_idx}/{lib_idx}_{mzml}.gz.cpickle.zlib", lib_idx=idotp_check_indices, mzml=[fn for fn in config[0]]))
    benchmark:
        "results/benchmarks/mv_passing_tensors.benchmark.txt"
    script:
        "scripts/HDX_LIMIT/pipeline/mv_passing_tensors.py"

if config['polyfit_calibration']:
    rule extract_tensors:
        input:
            library_info_fn,
            "resources/mzml/{mzml}.gz",
            "config/config.yaml",
            expand(
                "results/imtbx/{undeut_fn}_mz_calib_dict.pk", undeut_fn=config[0][0]
            ),
            "resources/idotp_filter/filter_passing_indices.csv"
        output:
            expand(
                "resources/passing_tensors/{lib_idx}/{lib_idx}_{{mzml}}.gz.cpickle.zlib",
                lib_idx=idotp_check_indices
            )
        benchmark:
            "results/benchmarks/extract_tensors.{mzml}.gz.benchmark.txt"
        
        script:
            "scripts/HDX_LIMIT/pipeline/extract_timepoint_tensors.py"
else:
    rule extract_tensors:
        input:
            library_info_fn,
            "resources/mzml/{mzml}.gz",
            "config/config.yaml",
            "resources/idotp_filter/filter_passing_indices.csv"
        output:
            expand(
                "resources/passing_tensors/{lib_idx}/{lib_idx}_{{mzml}}.gz.cpickle.zlib",
                lib_idx=idotp_check_indices
            ),
        benchmark:
            "results/benchmarks/extract_tensors.{mzml}.gz.benchmark.txt"
        script:
            "scripts/HDX_LIMIT/pipeline/extract_timepoint_tensors.py"


rule generate_tensor_ics:
    # TODO: docstring
    input:
        library_info_fn,
        "resources/passing_tensors/{lib_idx}/{lib_idx}_{file}.cpickle.zlib",
        "config/config.yaml"
    output:
        "resources/subtensor_ics/{lib_idx}/{lib_idx}_{file}.cpickle.zlib",
        "results/plots/factors/{lib_idx}_{file}.cpickle.zlib.factor.pdf"
    benchmark:
        "results/benchmarks/generate_subtensor_ics.{lib_idx}_{file}.benchmark.txt"
    shell:
        "python workflow/scripts/HDX_LIMIT/pipeline/generate_tensor_ics.py {input[0]} {input[1]} {input[2]} --isotope_clusters_out_path {output[0]} --factor_plot_out_path {output[1]}"

rule optimize_paths:
    input:
        library_info_fn,
        "config/config.yaml"
        lambda wildcards: optimize_paths_inputs(wildcards.name, library_info, idotp_check_indices) 
    output:
        "results/plots/ic_time_series/html/{name}_time_series.html",
        "resources/ic_time_series/{name}_winner.cpickle.zlib",
        "resources/ic_time_series/{name}_runners.cpickle.zlib",
        "resources/ic_time_series/{name}_undeut_grounds.cpickle.zlib",
        "resources/ic_time_series/{name}_winner_scores.cpickle.zlib",
        "resources/ic_time_series/{name}_rtdt_com_cvs.cpickle.zlib",
    benchmark:
        "results/benchmarks/optimize_paths.{name}.benchmark.txt"
    run:
        inputs = [input[i] for i in range(2, len(input))]
        shell('''
            python workflow/scripts/HDX_LIMIT/pipeline/optimize_paths.py {input[0]} {input[1]} --all_ic_input_paths {inputs} --html_plot_out_path {output[0]} --winner_out_path {output[1]} --runner_out_path {output[2]} --undeut_ground_out_path {output[3]} --winner_scores_out_path {output[4]} --rtdt_com_cvs_out_path {output[5]}
        ''')

"""
#REVIEW FUNCTIONALITY
rule make_overview_plot:
    input:
        expand("resources/ic_time_series/{name}_winner.cpickle.zlib", name=names),  #subset_names),
        expand(
            "resources/ic_time_series/{name}_undeut_grounds.cpickle.zlib", name=names
        ),
        #subset_names),
        expand("resources/ic_time_series/{name}_winner_scores.cpickle.zlib", name=names),  #subset_names),
        expand("resources/ic_time_series/{name}_rtdt_com_cvs.cpickle.zlib", name=names)  #subset_names)
    output:
        "results/plots/" + config["run_name"] + "_overview.html",
    benchmark:
        "results/benchmarks/make_overview_plot.benchmark.txt"
    shell:
        "python scripts/main/overview_plotter.py"


#TO BE REMOVED WHEN gjr_plot is included in PO
rule gjr_plots:
    input:
        "resources/ic_time_series/{name}_winner.cpickle.zlib",
        "resources/ic_time_series/{name}_runners.cpickle.zlib",
        "resources/ic_time_series/{name}_undeut_grounds.cpickle.zlib",
    output:
        "results/plots/ic_time_series/gjr_plots/{name}_gjr_plot.pdf",
    benchmark:
        "results/benchmarks/gjr_plot_{name}.benchmark.txt"
    script:
        "scripts/main/gjr_plot.py"

#TO BE REVIEWED FOR FUNCTION
rule make_plot_linker:
    input:
        "results/plots/" + config["run_name"] + "_overview.html",
        expand("results/plots/ic_time_series/html/{name}_time_series.html", name=names),  #subset_names)
    output:
        config["run_name"] + "_plot_linker.html",
    benchmark:
        "results/benchmarks/make_plot_linker.benchmark.txt"
    script:
        "scripts/main/plot_linker.py"

#PLACEHOLDER
rule calculate_hdx_rates:
    input:
        "resources/ic_time_series/{name}_winner.cpickle.zlib",
    output:
        "resources/rates/{name}_rates.ext",  #idk ext atm
    benchmark:
        "results/benchmarks/calculate_hdx_rates.{name}.benchmark.txt"
    script:
        "scripts/main/hxrates.py"
"""
