# Define config file and import libraries
configfile: "config/config.yaml"
import glob

import pandas as pd
from collections import OrderedDict

# Read list of candidate POI charge states produced by preprocessing snakefile
library_info = pd.read_csv("resources/library_info/library_info.csv")
names = list(set(library_info["name"].values))

# mzml list
mzml_list = []
for tp in config["timepoints"]:
    for fn in config[tp]:
        mzml_list.append(fn)

def idotp_check_inputs(i):
    # Writes inputs for idotp_check rule based on library_info index
    idx_inputs = []
    if len(config[0]) > 1:
        for file in config[0]:
            idx_inputs.append(
                "resources/tensors/" + str(i) + "/" + str(i) + "_" + file + ".gz.cpickle.zlib"
            )
    else:
        file = config[0][0]
        idx_inputs.append(
            "resources/tensors/" + str(i) + "/" + str(i) + "_" + file + ".gz.cpickle.zlib"
        )
    return idx_inputs

rule all:
    input:
        "resources/library_info/filter_passing_indices.csv"


if config['polyfit_calibration']:
    rule extract_tensors:
        input:
            "resources/library_info/library_info.csv",
            "resources/mzml/{mzml}.gz",
            "config/config.yaml",
            expand(
                "results/imtbx/{undeut_fn}_mz_calib_dict.pk", undeut_fn=config[0][0]
            )
        output:
            expand(
                "resources/tensors/{idx}/{idx}_{{mzml}}.gz.cpickle.zlib",
                idx=range(len(library_info))
            )
        benchmark:
            "results/benchmarks/extract_tensors.{mzml}.gz.benchmark.txt"

        script:
            "scripts/HDX_LIMIT/pipeline/extract_timepoint_tensors.py"

else:
    rule extract_tensors:
        input:
            "resources/library_info/library_info.csv",
            "resources/mzml/{mzml}.gz",
            "config/config.yaml"
        output:
            expand(
                "resources/tensors/{idx}/{idx}_{{mzml}}.gz.cpickle.zlib",
                idx=range(len(library_info))
            )
        benchmark:
            "results/benchmarks/extract_tensors.{mzml}.gz.benchmark.txt"
        script:
            "scripts/HDX_LIMIT/pipeline/extract_timepoint_tensors.py"

rule idotp_check:
    # TODO: docstring
    input:
        "resources/library_info/library_info.csv",
        lambda wildcards: idotp_check_inputs(wildcards.i),
    output:
        "resources/idotp_filter/{i}_idotp_check.csv",
        expand("resources/factor_data/{{i}}_{file}.cpickle.zlib.factor", file=config[0])
        expand("results/plots/factors/{{i}}_{file}.cpickle.zlib.factor.pdf", file=config[0])
    benchmark:
        "results/benchmarks/idotp_check.{i}.benchmark.txt"
    run:
        inputs = [input[i] for i in range(1, len(input))]
        outputs_factor_dict = [output[i] for i in range(1, len(output)) if output[i].endswith(".factor")]
        outputs_factor_plot = [output[i] for i in range(1, len(output)) if output[i].endswith(".factor.pdf")]
        shell('''
            python workflow/scripts/HDX_LIMIT/pipeline/idotp_check.py {input[0]} {inputs} {output[0]} {outputs_factor_dict} {outputs_factor_plot}
        ''')

rule idotp_filter:
    input: 
        "resources/library_info/library_info.csv",
        expand("resources/idotp_filter/{i}_idotp_check.csv", i=range(len(library_info)))
    output:
        "resources/library_info/filter_passing_indices.csv"

    run:
        inputs = [input[i] for i in range(1, len(input))]
        shell('''
            python workflow/scripts/HDX_LIMIT/pipeline/idotp_filter.py --all_idotp_csv_inputs "{inputs}" --out_path {output}
        ''')

