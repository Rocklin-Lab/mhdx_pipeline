# Define config file and import libraries
configfile: "config/config.yaml"
import glob

import pandas as pd
from collections import OrderedDict

# Read list of candidate POI charge states produced by preprocessing snakefile
library_info_fn = "resources/library_info/library_info.json"
library_info = pd.read_json(library_info_fn)
names = list(set(library_info["name"].values))

# mzml list
mzml_list = []
for tp in config["timepoints"]:
    for fn in config[tp]:
        mzml_list.append(fn)

def idotp_check_inputs(i):
    # Writes inputs for idotp_check rule based on library_info index
    idx_inputs = []
    if len(config[0]) > 1:
        for file in config[0]:
            idx_inputs.append(
                "resources/tensors/" + str(i) + "/" + str(i) + "_" + file + ".gz.cpickle.zlib"
            )
    else:
        file = config[0][0]
        idx_inputs.append(
            "resources/tensors/" + str(i) + "/" + str(i) + "_" + file + ".gz.cpickle.zlib"
        )
    return idx_inputs

rule all:
    input:
        "resources/idotp_filter/filter_passing_indices.csv",
        library_info_fn


if config['polyfit_calibration']:
    rule extract_tensors:
        input:
            library_info_fn,
            "resources/mzml/{mzml}.gz",
            "config/config.yaml",
            expand(
                "results/imtbx/{undeut_fn}_mz_calib_dict.pk", undeut_fn=config[0][0]
            )
        output:
            expand(
                "resources/tensors/{idx}/{idx}_{{mzml}}.gz.cpickle.zlib",
                idx=range(len(library_info))
            )
        benchmark:
            "results/benchmarks/extract_tensors.{mzml}.gz.benchmark.txt"

        script:
            "scripts/HDX_LIMIT/pipeline/extract_timepoint_tensors.py"

else:
    rule extract_tensors:
        input:
            library_info_fn,
            "resources/mzml/{mzml}.gz",
            "config/config.yaml"
        output:
            expand(
                "resources/tensors/{idx}/{idx}_{{mzml}}.gz.cpickle.zlib",
                idx=range(len(library_info))
            )
        benchmark:
            "results/benchmarks/extract_tensors.{mzml}.gz.benchmark.txt"
        script:
            "scripts/HDX_LIMIT/pipeline/extract_timepoint_tensors.py"

rule idotp_check:
    # TODO: docstring
    input:
        library_info_fn,
        "config/config.yaml",
        lambda wildcards: idotp_check_inputs(wildcards.i),
    output:
        "resources/idotp_check/{i}_idotp_check.csv",
        #expand("resources/factor_data/{{i}}_{file}.cpickle.zlib.factor", file=config[0]),
        expand("results/plots/factors/{{i}}_{file}.cpickle.zlib.factor.pdf", file=config[0])
    benchmark:
        "results/benchmarks/idotp_check.{i}.benchmark.txt"
    run:
        inputs = [input[i] for i in range(2, len(input))]
        #outputs_factor_dict = [output[i] for i in range(1, len(output)) if output[i].endswith(".factor")]
        outputs_factor_plot = [output[i] for i in range(1, len(output)) if output[i].endswith(".factor.pdf")]
        shell('''
            python workflow/scripts/HDX_LIMIT/pipeline/idotp_check.py {input[1]} {input[0]} --undeut_tensor_path_list {inputs} --output_path {output[0]} --factor_plot_output_path {outputs_factor_plot}
        ''')

rule idotp_filter:
    input: 
        library_info_fn,
        expand("resources/idotp_check/{i}_idotp_check.csv", i=range(len(library_info)))
    output:
        "resources/idotp_filter/filter_passing_indices.csv",
        "resources/idotp_filter/checked_library_info.json",
        "results/plots/idotp_distribution.png"
    script:
        "scripts/HDX_LIMIT/pipeline/idotp_filter.py"

