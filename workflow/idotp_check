# Define config file and import libraries
configfile: "config/config.yaml"
import glob

import pandas as pd
from collections import OrderedDict

# Read list of candidate POI charge states produced by preprocessing snakefile
library_info = pd.read_csv("resources/library_info/library_info.csv")
names = list(set(library_info["name"].values))

# mzml list
mzml_list = []
for tp in config["timepoints"]:
    for fn in config[tp]:
        mzml_list.append(fn)

def idotp_check_inputs(i):
    # Writes inputs for idotp_check rule based on library_info index
    idx_inputs = []
    if len(config[0]) > 1:
        for file in config[0]:
            idx_inputs.append(
                "resources/tensors/" + str(i) + "_" + file + ".gz.cpickle.zlib"
            )
    else:
        file = config[0][0]
        idx_inputs.append(
            "resources/tensors/" + str(i) + "_" + file + ".gz.cpickle.zlib"
        )
    return idx_inputs

rule all:
    input:
        "resources/library_info/filter_passing_indices.csv"


if config['polyfit_calibration']:
    rule extract_tensors:
        input:
            "resources/library_info/library_info.csv",
            "resources/mzml/{mzml}.gz",
            "config/config.yaml",
            expand(
                "results/imtbx/{undeut_fn}_mz_calib_dict.pk", undeut_fn=config[0][0]
            )
        output:
            expand(
                "resources/tensors/{idx}_{{mzml}}.gz.cpickle.zlib",
                idx=range(len(library_info))
            )
        benchmark:
            "results/benchmarks/extract_tensors.{mzml}.gz.benchmark.txt"

        run:
            outputs = [output[i] for i in range(len(output))]
            shell('''
                python workflow/scripts/HDX_LIMIT/pipeline/extract_timepoint_tensors.py {input[0]} {input[1]} {input[2]}--polyfit_calibration_dict {input[3]} --outputs {outputs}
            ''')

else:
    rule extract_tensors:
        input:
            "resources/library_info/library_info.csv",
            "resources/mzml/{mzml}.gz",
            "config/config.yaml"
        output:
            expand(
                "resources/tensors/{idx}_{{mzml}}.gz.cpickle.zlib",
                idx=range(len(library_info))
            )
        benchmark:
            "results/benchmarks/extract_tensors.{mzml}.gz.benchmark.txt"
        run:
            outputs = [output[i] for i in range(len(output))]
            shell('''
                python workflow/scripts/HDX_LIMIT/pipeline/extract_timepoint_tensors.py {input[0]} {input[1]} {input[2]} --outputs {outputs}
            ''')

rule idotp_check:
    # TODO: docstring
    input:
        "resources/library_info/library_info.csv",
        lambda wildcards: idotp_check_inputs(wildcards.i),
    output:
        "resources/idotp_filter/{i}_idotp_check.csv",
    benchmark:
        "results/benchmarks/idotp_check.{i}.benchmark.txt"
    run:
        inputs = [input[1] for i in range(1, len(input))]
        shell('''
            python workflow/scripts/HDX_LIMIT/pipeline/idotp_check.py {input[0]} {inputs} {output}
        ''')

rule idotp_filter:
    input: 
        "resources/library_info/library_info.csv",
        expand("resources/idotp_filter/{i}_idotp_check.csv", i=range(len(library_info)))
    output:
        "resources/library_info/filter_passing_indices.csv"

    run:
        inputs = [input[i] for i in range(1, len(input))]
        shell('''
            "python workflow/HDX_LIMIT/pipeline/idotp_filter.py {input[0]} --all_idotp_csv_inputs {inputs} --out_path {output}"
        ''')

